# ğŸ§¬ Biomedical Active Learning: Achieving Superior Performance with Minimal Labels

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![GitHub stars](https://img.shields.io/github/stars/yusufmo1/biomedical-active-learning?style=social)](https://github.com/yusufmo1/biomedical-active-learning)
[![GitHub forks](https://img.shields.io/github/forks/yusufmo1/biomedical-active-learning?style=social)](https://github.com/yusufmo1/biomedical-active-learning)
[![TensorFlow 2.13+](https://img.shields.io/badge/tensorflow-2.13+-orange.svg)](https://tensorflow.org/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.3.0+-blue.svg)](https://scikit-learn.org/)
[![Docker](https://img.shields.io/badge/docker-ready-blue.svg)](https://hub.docker.com/)
[![Streamlit](https://img.shields.io/badge/streamlit-app-red.svg)](https://streamlit.io/)

**Active Learning outperforms full-data training**: Query-by-Committee with just 5 initial samples achieves **MCC 0.942** vs full model's **0.9253** on Breast Cancer dataset.

> ğŸŒŸ **Star this repository** if you find it useful for your research or applications!  
> ğŸ”„ **Fork it** to contribute improvements and extensions!  
> ğŸ“‹ **Open issues** for questions, suggestions, or collaboration opportunities!

## ğŸ¯ Key Results

Our active learning approach demonstrates that intelligent sample selection can match or exceed the performance of models trained on entire datasets:

### Performance Highlights

| Dataset | Method | MCC | F1 Score | ROC AUC | Initial Samples |
|---------|--------|-----|----------|---------|-----------------|
| **Breast Cancer** | QBC Full Model | 0.9254 | 0.9647 | 0.9958 | All (455) |
| **Breast Cancer** | **QBC First5** | **0.942** â­ | **0.9727** | **0.9965** | **5** |
| **Blood-Brain Barrier** | RF Full Model | 0.6547 | 0.8415 | 0.9174 | All (2,232) |
| **Blood-Brain Barrier** | QBC First5 | 0.6448 | 0.8349 | 0.9152 | 5 |

### Key Achievements

- ğŸš€ **Superior Performance**: QBC with 5 samples outperforms full dataset training on Breast Cancer
- ğŸ“Š **Statistical Parity**: Overlapping confidence intervals confirm AL matches full-data performance
- âš¡ **Rapid Convergence**: Models achieve peak performance within 5-10 iterations
- ğŸ¯ **Robust Results**: Consistent performance across 10 independent runs

## ğŸš€ Quick Start

```bash
# Clone repository
git clone https://github.com/yusufmo1/biomedical-active-learning.git
cd biomedical-active-learning

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Prepare datasets
python scripts/prepare_data.py --dataset breast_cancer --output-dir data/processed

# Run active learning experiments
python scripts/run_experiments.py --dataset breast_cancer --strategy qbc --runs 3

# Generate visualizations and reports
python scripts/evaluate.py --results-dir results/ --output-dir results/figures
python scripts/generate_report.py --format html --output results/report.html

# Launch interactive app
streamlit run app.py
```

## ğŸ“Š Project Overview

This project demonstrates how active learning can dramatically reduce annotation requirements in biomedical machine learning while maintaining or improving model performance. We evaluate two strategies across two challenging datasets:

### Datasets

<p align="center">
  <img src="docs/images/class_distribution_bbbp_bc.png" alt="Class Distribution" width="800"/>
</p>

1. **Blood-Brain Barrier Penetration (BBB)**
   - 2,790 molecules with SMILES representations
   - Binary classification: BBB+ vs BBB-
   - Features: RDKit descriptors + Mol2vec embeddings

2. **Breast Cancer Wisconsin**
   - 569 samples with 30 features
   - Binary classification: Malignant vs Benign
   - Features: Cell nucleus characteristics

### Active Learning Strategies

- **Random Forest (RF)**: Single learner with uncertainty sampling
- **Query-by-Committee (QBC)**: Ensemble of 5 diverse classifiers using vote entropy

## ğŸ”¬ Methodology

### 1. Data Preprocessing

#### Feature Analysis and Visualization

<p align="center">
  <img src="docs/images/pairplot_bbbp.png" alt="BBB Feature Pairplot" width="800"/>
</p>

<p align="center">
  <img src="docs/images/pairplot_bc.png" alt="Breast Cancer Feature Pairplot" width="800"/>
</p>

#### Blood-Brain Barrier Dataset
```python
# SMILES validation and featurization
- RDKit molecular descriptors
- Mol2vec embeddings (300 dimensions)
- Feature cleaning and normalization
```

<p align="center">
  <img src="docs/images/cumalative_pc_explain_bbbp.png" alt="BBB PCA Variance Explained" width="600"/>
</p>

#### Breast Cancer Dataset
```python
# Standard preprocessing pipeline
- Target encoding (Mâ†’1, Bâ†’0)
- Feature scaling with StandardScaler
- Train/test split (80/20)
```

### 2. Active Learning Pipeline

```python
# Initialization strategies
- First 5: Select first 5 samples from dataset
- Stratified 5: Stratified sampling of 5 samples

# Query strategies
- Least Confidence: Select most uncertain samples
- Vote Entropy: Maximum disagreement among committee

# Batch size: 20 samples per iteration
# Stopping criterion: 100% of pool queried
```

### 3. Evaluation Metrics

- **Matthews Correlation Coefficient (MCC)**: Primary metric for imbalanced data
- **F1 Score**: Harmonic mean of precision and recall
- **ROC AUC**: Area under the receiver operating characteristic curve
- **Delta MCC (DMCC)**: Improvement over baseline

## ğŸ“ˆ Detailed Results

### Active Learning Comparison: RF vs QBC

<p align="center">
  <img src="docs/images/al_bbbp_comparison_rf_vs_qbc.png" alt="BBBP AL Comparison" width="800"/>
</p>

<p align="center">
  <img src="docs/images/al_bc_comparison_rf_vs_qbc.png" alt="Breast Cancer AL Comparison" width="800"/>
</p>

### Delta MCC Evolution

The evolution of Delta MCC (DMCC) shows how active learning performance improves relative to baseline:

<p align="center">
  <img src="docs/images/dmcc_evolution_bbbp.png" alt="BBBP DMCC Evolution" width="800"/>
</p>

<p align="center">
  <img src="docs/images/dmcc_evolution_bc.png" alt="Breast Cancer DMCC Evolution" width="800"/>
</p>

### Confusion Matrices: Active Learning vs Full Model

<p align="center">
  <img src="docs/images/confusion_matrix_al_vs_full_bbbp.png" alt="BBBP Confusion Matrices" width="800"/>
</p>

<p align="center">
  <img src="docs/images/confusion_matrix_al_vs_full_bc.png" alt="Breast Cancer Confusion Matrices" width="800"/>
</p>

### ROC Curves

<p align="center">
  <img src="docs/images/roc._bbbp_bcpng.png" alt="ROC Curves" width="800"/>
</p>

### Statistical Analysis

<p align="center">
  <img src="docs/images/p-val-combo_bbbp_bc.png" alt="Statistical Significance Analysis" width="800"/>
</p>

### Dimensionality Reduction Analysis

#### PCA Visualization
<p align="center">
  <img src="docs/images/pca_bbbp_bc.png" alt="PCA Analysis" width="800"/>
</p>

#### t-SNE Visualization
<p align="center">
  <img src="docs/images/t-sne_bbbp_bc.png" alt="t-SNE Analysis" width="800"/>
</p>

#### UMAP Visualization
<p align="center">
  <img src="docs/images/umap_bbbp_bc.png" alt="UMAP Analysis" width="800"/>
</p>

#### LDA Visualization
<p align="center">
  <img src="docs/images/lda_bbbp_bc.png" alt="LDA Analysis" width="800"/>
</p>

### Performance Summary

#### Blood-Brain Barrier Permeability
| Strategy | MCC | F1 Score | ROC AUC | DMCC |
|----------|-----|----------|---------|------|
| RF Full Model | 0.6547 Â± 0.0384 | 0.8415 | 0.9174 | - |
| RF First5 | 0.6203 Â± 0.0298 | 0.8146 | 0.9122 | -0.0783 |
| RF Stratified | 0.6535 Â± 0.0130 | 0.8383 | 0.9166 | -0.0012 |
| QBC Full Model | 0.6341 Â± 0.0123 | 0.8295 | 0.9130 | - |
| QBC First5 | 0.6448 Â± 0.0193 | 0.8349 | 0.9152 | -0.0538 |
| QBC Stratified | 0.6382 Â± 0.0101 | 0.8311 | 0.9141 | +0.0041 |

#### Breast Cancer
| Strategy | MCC | F1 Score | ROC AUC | DMCC |
|----------|-----|----------|---------|------|
| RF Full Model | 0.9253 | 0.9647 | 0.9964 | - |
| RF First5 | 0.9230 Â± 0.0051 | 0.9634 Â± 0.0026 | 0.9958 Â± 0.0003 | -0.0023 |
| RF Stratified | 0.9244 Â± 0.0038 | 0.9641 Â± 0.0019 | 0.9961 Â± 0.0003 | -0.0009 |
| QBC Full Model | 0.9254 Â± 0.0056 | 0.9647 Â± 0.0028 | 0.9958 Â± 0.0003 | - |
| **QBC First5** | **0.942 Â± 0.0059** â­ | **0.9727 Â± 0.0028** | **0.9965 Â± 0.0002** | **+0.0168** |
| QBC Stratified | 0.9252 Â± 0.0057 | 0.9646 Â± 0.0029 | 0.9959 Â± 0.0003 | -0.0002 |

## ğŸ’» Installation

### Requirements

- Python 3.8+
- CUDA-capable GPU (optional, for faster training)

### Detailed Setup

```bash
# Clone the repository
git clone https://github.com/yusufmo1/biomedical-active-learning.git
cd biomedical-active-learning

# Create and activate virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Download molecular models (for BBB dataset)
python scripts/download_models.py

# Prepare datasets
python scripts/prepare_data.py --all

# Run tests to verify installation
pytest tests/
```

## ğŸ® Usage

### ğŸ³ Docker Deployment (Recommended)

The fastest way to get started is using Docker:

```bash
# Launch all services (Streamlit app, Jupyter, Redis cache)
docker-compose up -d

# Access applications
# Streamlit Interactive App: http://localhost:8501
# Jupyter Notebooks: http://localhost:8888
# Stop services: docker-compose down
```

### ğŸ“± Interactive Streamlit Application

Launch our comprehensive web application with all features:

```bash
streamlit run app.py
```

**Features:**
- **ğŸ  Home Dashboard**: Performance metrics and key visualizations
- **ğŸ” Data Exploration**: Interactive dataset analysis with statistical summaries
- **ğŸ¤– Active Learning Demo**: Real-time simulation of AL strategies
- **ğŸ“Š Results Comparison**: Statistical analysis with confidence intervals
- **ğŸ¯ Model Predictions**: Upload data for real-time predictions

### Command Line Interface

Our project provides comprehensive CLI tools for all major operations:

#### 1. Data Preparation
```bash
# Prepare Blood-Brain Barrier dataset
python scripts/prepare_data.py --dataset bbb --output-dir data/processed --mol2vec-model data/external/mol2vec_model_300dim.pkl

# Prepare Breast Cancer dataset
python scripts/prepare_data.py --dataset breast_cancer --output-dir data/processed

# Prepare both datasets
python scripts/prepare_data.py --dataset all
```

#### 2. Running Experiments
```bash
# Single experiment
python scripts/run_experiments.py --dataset breast_cancer --strategy qbc --sampling first_5 --runs 10

# Multiple strategies comparison
python scripts/run_experiments.py --dataset bbb --strategy rf qbc --sampling first_5 stratified --runs 10

# Custom configuration
python scripts/run_experiments.py --config configs/experiment_config.yaml --parallel --verbose
```

#### 3. Evaluation and Visualization
```bash
# Generate all visualizations
python scripts/evaluate.py --results-dir results/ --output-dir results/figures --plots all

# Specific analysis
python scripts/evaluate.py --plots learning_curves dmcc_evolution confusion_matrix

# Statistical analysis
python scripts/evaluate.py --statistical-tests --confidence-level 0.95
```

#### 4. Report Generation
```bash
# Generate HTML report
python scripts/generate_report.py --format html --output results/comprehensive_report.html

# Generate PDF report (requires LaTeX)
python scripts/generate_report.py --format pdf --output results/publication_report.pdf

# Generate Markdown summary
python scripts/generate_report.py --format markdown --output results/summary.md
```

### Python API Usage

```python
from src.active_learning.experiments import ALExperiment
from src.data.loader import DatasetLoader
from src.evaluation.metrics import ModelEvaluator

# Load dataset
loader = DatasetLoader()
X_train, X_test, y_train, y_test = loader.load_breast_cancer()

# Run active learning experiment
experiment = ALExperiment(
    strategy='qbc',
    sampling_method='first_5',
    batch_size=10,
    n_runs=10
)

results = experiment.run_experiment(X_train, y_train, X_test, y_test)

# Evaluate results
evaluator = ModelEvaluator()
metrics = evaluator.evaluate_experiment_results(results)
print(f"Best MCC: {metrics['best_mcc']:.4f}")
```

### Interactive Notebooks

Explore the project through our organized notebooks:

1. **[Data Exploration](notebooks/01_data_exploration.ipynb)**: Dataset inspection and analysis
2. **[Preprocessing](notebooks/02_preprocessing.ipynb)**: Feature engineering and data preparation
3. **[Dimensionality Reduction](notebooks/03_dimensionality_reduction.ipynb)**: PCA, t-SNE, UMAP, LDA analysis
4. **[Active Learning Experiments](notebooks/04_active_learning_experiments.ipynb)**: Complete experimental pipeline
5. **[Results Analysis](notebooks/05_results_analysis.ipynb)**: Statistical analysis and visualization
6. **[Quick Demo](notebooks/quick_demo.ipynb)**: Fast overview of key results

### ğŸ§ª Testing

Comprehensive test suite with 100% coverage:

```bash
# Run all tests
pytest tests/

# Run with coverage
pytest tests/ --cov=src --cov-report=html

# Run specific test modules
pytest tests/test_experiments.py -v
```

**Test Coverage:**
- âœ… Unit tests for all core modules
- âœ… Integration tests for complete pipelines
- âœ… Performance and memory usage tests
- âœ… Mock datasets for fast testing
- âœ… Edge case and error handling tests

## ğŸ“ Project Structure

```
biomedical-active-learning/
â”œâ”€â”€ ğŸ“‹ app.py                          # Streamlit web application
â”œâ”€â”€ ğŸ³ Dockerfile                      # Multi-stage container build
â”œâ”€â”€ ğŸ³ docker-compose.yml              # Full stack deployment
â”œâ”€â”€ ğŸ“ requirements.txt                # Python dependencies
â”œâ”€â”€ ğŸ“„ README.md                       # Project documentation
â”œâ”€â”€ ğŸ“„ LICENSE                         # MIT license
â”œâ”€â”€ .github/workflows/                  # CI/CD pipelines
â”œâ”€â”€ configs/                           # Configuration files
â”‚   â”œâ”€â”€ data_config.yaml               # Dataset configurations
â”‚   â”œâ”€â”€ experiment_config.yaml         # Experiment parameters
â”‚   â””â”€â”€ model_config.yaml              # Model hyperparameters
â”œâ”€â”€ data/                              # Data storage
â”‚   â”œâ”€â”€ raw/                           # Original datasets
â”‚   â”œâ”€â”€ processed/                     # Cleaned and preprocessed
â”‚   â””â”€â”€ external/                      # External models (Mol2vec)
â”œâ”€â”€ docs/                              # Documentation
â”‚   â”œâ”€â”€ images/                        # Result visualizations
â”‚   â”œâ”€â”€ methodology.md                 # Detailed methodology
â”‚   â”œâ”€â”€ results.md                     # Comprehensive results
â”‚   â”œâ”€â”€ api.md                         # API documentation
â”‚   â””â”€â”€ deployment.md                  # Deployment guide
â”œâ”€â”€ models/                            # Trained models
â”œâ”€â”€ notebooks/                         # Jupyter analysis notebooks
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb      # Dataset analysis
â”‚   â”œâ”€â”€ 02_preprocessing.ipynb         # Feature engineering
â”‚   â”œâ”€â”€ 03_dimensionality_reduction.ipynb # PCA, t-SNE, UMAP, LDA
â”‚   â”œâ”€â”€ 04_active_learning_experiments.ipynb # Full experiments
â”‚   â”œâ”€â”€ 05_results_analysis.ipynb      # Statistical analysis
â”‚   â””â”€â”€ quick_demo.ipynb               # Quick start demo
â”œâ”€â”€ results/                           # Experiment outputs
â”‚   â”œâ”€â”€ figures/                       # Generated visualizations
â”‚   â””â”€â”€ metrics/                       # Performance metrics
â”œâ”€â”€ scripts/                           # Command-line tools
â”‚   â”œâ”€â”€ prepare_data.py                # Data preprocessing
â”‚   â”œâ”€â”€ run_experiments.py             # Experiment execution
â”‚   â”œâ”€â”€ evaluate.py                    # Results evaluation
â”‚   â””â”€â”€ generate_report.py             # Report generation
â”œâ”€â”€ src/                               # Core library code
â”‚   â”œâ”€â”€ active_learning/               # AL strategies and experiments
â”‚   â”‚   â”œâ”€â”€ strategies.py              # Sampling strategies
â”‚   â”‚   â”œâ”€â”€ learners.py                # AL learner classes
â”‚   â”‚   â””â”€â”€ experiments.py             # Experiment framework
â”‚   â”œâ”€â”€ data/                          # Data loading and preprocessing
â”‚   â”‚   â”œâ”€â”€ loader.py                  # Dataset loading utilities
â”‚   â”‚   â””â”€â”€ preprocessing.py           # Preprocessing pipelines
â”‚   â”œâ”€â”€ features/                      # Feature engineering
â”‚   â”‚   â””â”€â”€ molecular.py               # Molecular featurization
â”‚   â”œâ”€â”€ evaluation/                    # Evaluation and visualization
â”‚   â”‚   â”œâ”€â”€ metrics.py                 # Performance metrics
â”‚   â”‚   â””â”€â”€ visualization.py           # Plotting utilities
â”‚   â”œâ”€â”€ dimensionality/                # Dimensionality reduction
â”‚   â”‚   â””â”€â”€ reduction.py               # PCA, t-SNE, UMAP, LDA
â”‚   â””â”€â”€ utils/                         # General utilities
â”‚       â”œâ”€â”€ config.py                  # Configuration management
â”‚       â”œâ”€â”€ helpers.py                 # Helper functions
â”‚       â””â”€â”€ parallel.py                # Parallel processing
â””â”€â”€ tests/                             # Test suite
    â”œâ”€â”€ conftest.py                    # Test configuration
    â”œâ”€â”€ fixtures/                      # Mock datasets
    â”œâ”€â”€ test_data_loader.py            # Data loading tests
    â”œâ”€â”€ test_preprocessing.py          # Preprocessing tests
    â”œâ”€â”€ test_molecular.py              # Molecular features tests
    â”œâ”€â”€ test_strategies.py             # Sampling strategy tests
    â”œâ”€â”€ test_learners.py               # Learner class tests
    â”œâ”€â”€ test_evaluation.py             # Evaluation tests
    â”œâ”€â”€ test_experiments.py            # Experiment tests
    â””â”€â”€ test_integration.py            # Integration tests
```

## ğŸš€ Features Overview

### ğŸ”¬ Core Research Components
- **Advanced Active Learning**: RF uncertainty sampling + QBC vote entropy
- **Molecular Featurization**: RDKit descriptors + Mol2vec embeddings
- **Statistical Analysis**: MCC, F1, ROC AUC with confidence intervals
- **Dimensionality Reduction**: PCA, t-SNE, UMAP, LDA analysis

### ğŸ’» Software Engineering Excellence
- **Production-Ready Code**: Modular architecture with proper abstractions
- **Interactive Web App**: Streamlit dashboard with real-time analysis
- **Comprehensive Testing**: 100% test coverage with unit/integration tests
- **Container Deployment**: Docker with multi-stage builds and security
- **CI/CD Ready**: GitHub Actions workflows for automated testing
- **Extensive Documentation**: API docs, methodology, and deployment guides

### ğŸ“Š Analysis and Visualization
- **Statistical Significance**: Error bars and confidence intervals
- **Learning Curves**: Performance evolution over iterations
- **Confusion Matrices**: Detailed classification analysis
- **Feature Importance**: PCA variance and molecular descriptors
- **Interactive Plots**: Streamlit-powered data exploration


## ğŸ“– Citation

If you use this code in your research, please cite:

```bibtex
@software{biomedical_active_learning2025,
  author = {Mohammed, Yusuf},
  title = {Biomedical Active Learning: Superior Performance with Minimal Labels},
  year = {2025},
  publisher = {GitHub},
  journal = {GitHub repository},
  url = {https://github.com/yusufmo1/biomedical-active-learning}
}
```

### Development Setup
```bash
# Fork the repository and clone your fork
git clone https://github.com/YOUR_USERNAME/biomedical-active-learning.git
cd biomedical-active-learning

# Install development dependencies
pip install -r requirements.txt
pip install -e .

# Run tests to ensure everything works
pytest tests/ -v

# Create a feature branch
git checkout -b feature/your-feature-name
```



## ğŸ™ Acknowledgments

- **Queen Mary University of London** for research support
- **RDKit** and **Mol2vec** teams for molecular featurization tools
- **scikit-learn** and **Optuna** communities
- **Open source contributors** who help improve this project

## ğŸ“„ License

This project is licensed under the MIT License - see [LICENSE](LICENSE) for details.

<p align="center">
  <strong>Contact</strong><br>
  <a href="https://github.com/yusufmo1">GitHub</a> â€¢ 
  <a href="https://www.linkedin.com/in/yusuf-mohammed1/">LinkedIn</a> â€¢ 
  Queen Mary University of London
</p>