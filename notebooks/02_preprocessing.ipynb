{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Data Preprocessing\n\nThis notebook demonstrates the preprocessing pipeline for both datasets:\n\n1. **BBB Dataset**: SMILES validation → RDKit descriptors → Mol2vec embeddings → Feature cleaning\n2. **Breast Cancer Dataset**: Standard preprocessing → Feature scaling → Train/test split\n\n## Key Steps:\n- Molecular featurization using RDKit and Mol2vec for BBB data\n- Standard scaling and splitting for clinical data\n- Feature importance analysis\n- Data quality checks and cleaning",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import sys\nimport os\nsys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'src'))\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Chemistry and molecular processing\nimport requests\nimport tarfile\nfrom rdkit import Chem\nfrom rdkit.Chem import Descriptors\nfrom rdkit.ML.Descriptors import MoleculeDescriptors\nfrom gensim.models import Word2Vec\n\nfrom data.preprocessing import BBBPreprocessor, BreastCancerPreprocessor\n\nprint(\"Libraries imported successfully!\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 1. Load Raw Datasets",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Load datasets\nbbb_df = pd.read_excel('../data/raw/BBBP.xlsx')\nbc_df = pd.read_csv('../data/raw/breast-cancer.csv')\n\nprint(\"Raw dataset shapes:\")\nprint(f\"BBB dataset: {bbb_df.shape}\")\nprint(f\"Breast Cancer dataset: {bc_df.shape}\")\n\n# Quick preview\nprint(f\"\\nBBB columns: {bbb_df.columns.tolist()}\")\nprint(f\"BC columns: {bc_df.columns.tolist()[:10]}...\")  # First 10 columns",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 2. BBB Dataset: Molecular Featurization\n\nThe BBB dataset requires specialized preprocessing:\n1. SMILES validation\n2. RDKit molecular descriptors\n3. Mol2vec embeddings\n4. Feature cleaning and consolidation",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Download Mol2vec model if needed\nmodel_path = \"../data/external/model_300dim.pkl\"\nif not os.path.exists(model_path):\n    print(\"Downloading Mol2vec model...\")\n    os.makedirs(os.path.dirname(model_path), exist_ok=True)\n    \n    # Download the file\n    url = \"https://deepchemdata.s3-us-west-1.amazonaws.com/trained_models/mol2vec_model_300dim.tar.gz\"\n    response = requests.get(url)\n    tar_path = \"../data/external/mol2vec_model_300dim.tar.gz\"\n    \n    with open(tar_path, \"wb\") as f:\n        f.write(response.content)\n\n    # Extract the tar.gz file\n    with tarfile.open(tar_path, \"r:gz\") as tar:\n        tar.extractall(\"../data/external/\")\n\n    # Rename the extracted file\n    extracted_path = \"../data/external/mol2vec_model_300dim.pkl\"\n    if os.path.exists(extracted_path):\n        os.rename(extracted_path, model_path)\n\n    # Clean up the tar.gz file\n    os.remove(tar_path)\n    print(\"Mol2vec model downloaded and extracted!\")\nelse:\n    print(\"Mol2vec model already exists!\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Process BBB dataset using the preprocessor\nprint(\"Processing BBB dataset...\")\nbbb_preprocessor = BBBPreprocessor()\n\n# Step 1: Load the Mol2vec model\nmol2vec_model = bbb_preprocessor.load_mol2vec_model(model_path)\nprint(f\"Mol2vec model loaded with {mol2vec_model.vector_size} dimensions\")\n\n# Step 2: Validate SMILES and compute features\ntry:\n    bbb_processed = bbb_preprocessor.process_dataset(bbb_df, mol2vec_model)\n    print(f\"BBB processing completed! Final shape: {bbb_processed.shape}\")\n    \n    # Show sample of processed features\n    print(f\"\\nProcessed feature types:\")\n    feature_columns = [col for col in bbb_processed.columns if col not in ['BBB', 'SMILES']]\n    print(f\"- RDKit descriptors: {len([c for c in feature_columns if not c.startswith('mol2vec')])}\")\n    print(f\"- Mol2vec features: {len([c for c in feature_columns if c.startswith('mol2vec')])}\")\n    print(f\"- Total features: {len(feature_columns)}\")\n    \nexcept Exception as e:\n    print(f\"Error processing BBB dataset: {e}\")\n    raise",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 3. Breast Cancer Dataset: Standard Preprocessing",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Process Breast Cancer dataset\nprint(\"Processing Breast Cancer dataset...\")\nbc_preprocessor = BreastCancerPreprocessor()\n\nbc_processed = bc_preprocessor.process_dataset(bc_df)\nprint(f\"BC processing completed! Final shape: {bc_processed.shape}\")\n\n# Show the processed dataset structure\nprint(f\"\\nBreast Cancer processed features:\")\nfeature_columns = [col for col in bc_processed.columns if col != 'target']\nprint(f\"- Number of features: {len(feature_columns)}\")\nprint(f\"- Feature names: {feature_columns[:5]}...\") # First 5 features\n\n# Check class distribution\nprint(f\"\\nClass distribution:\")\nprint(bc_processed['target'].value_counts())",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 4. Train/Test Splitting and Scaling",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# BBB Dataset splitting and scaling\nprint(\"=== BBB Dataset Splitting and Scaling ===\")\n\n# Separate features and target, preserving SMILES\nfeature_cols_bbb = [col for col in bbb_processed.columns if col not in ['BBB', 'SMILES']]\nX_bbb = bbb_processed[feature_cols_bbb]\ny_bbb = bbb_processed['BBB']\nsmiles_bbb = bbb_processed['SMILES']\n\nprint(f\"BBB features shape: {X_bbb.shape}\")\nprint(f\"BBB target shape: {y_bbb.shape}\")\n\n# Train/test split (80/20)\nX_bbb_train, X_bbb_test, y_bbb_train, y_bbb_test, smiles_train, smiles_test = train_test_split(\n    X_bbb, y_bbb, smiles_bbb, test_size=0.2, random_state=42, stratify=y_bbb\n)\n\n# Scale features\nscaler_bbb = StandardScaler()\nX_bbb_train_scaled = scaler_bbb.fit_transform(X_bbb_train)\nX_bbb_test_scaled = scaler_bbb.transform(X_bbb_test)\n\nprint(f\"BBB train set: {X_bbb_train_scaled.shape}\")\nprint(f\"BBB test set: {X_bbb_test_scaled.shape}\")\nprint(f\"BBB train target distribution: {np.bincount(y_bbb_train)}\")\nprint(f\"BBB test target distribution: {np.bincount(y_bbb_test)}\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Breast Cancer Dataset splitting and scaling\nprint(\"\\n=== Breast Cancer Dataset Splitting and Scaling ===\")\n\n# Separate features and target\nfeature_cols_bc = [col for col in bc_processed.columns if col != 'target']\nX_bc = bc_processed[feature_cols_bc]\ny_bc = bc_processed['target']\n\nprint(f\"BC features shape: {X_bc.shape}\")\nprint(f\"BC target shape: {y_bc.shape}\")\n\n# Train/test split (80/20)\nX_bc_train, X_bc_test, y_bc_train, y_bc_test = train_test_split(\n    X_bc, y_bc, test_size=0.2, random_state=42, stratify=y_bc\n)\n\n# Scale features\nscaler_bc = StandardScaler()\nX_bc_train_scaled = scaler_bc.fit_transform(X_bc_train)\nX_bc_test_scaled = scaler_bc.transform(X_bc_test)\n\nprint(f\"BC train set: {X_bc_train_scaled.shape}\")\nprint(f\"BC test set: {X_bc_test_scaled.shape}\")\nprint(f\"BC train target distribution: {np.bincount(y_bc_train)}\")\nprint(f\"BC test target distribution: {np.bincount(y_bc_test)}\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 5. Feature Importance Analysis",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Feature importance analysis using Random Forest\ndef analyze_feature_importance(X_train, y_train, feature_names, dataset_name, top_n=20):\n    \"\"\"Analyze and plot feature importance using Random Forest\"\"\"\n    \n    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n    rf.fit(X_train, y_train)\n    \n    # Get feature importances\n    importances = rf.feature_importances_\n    indices = np.argsort(importances)[::-1]\n    \n    print(f\"\\n{dataset_name} - Top {top_n} Feature Importances:\")\n    print(\"-\" * 60)\n    for i in range(min(top_n, len(indices))):\n        idx = indices[i]\n        feature_name = feature_names[idx] if hasattr(feature_names, '__getitem__') else f\"Feature_{idx}\"\n        print(f\"{i+1:2d}. {feature_name}: {importances[idx]:.4f}\")\n    \n    # Plot top features\n    plt.figure(figsize=(12, 8))\n    top_indices = indices[:top_n]\n    top_importances = importances[top_indices]\n    top_names = [feature_names[i] if hasattr(feature_names, '__getitem__') else f\"Feature_{i}\" \n                 for i in top_indices]\n    \n    # Clean up feature names for display\n    display_names = [name.replace('_', ' ') for name in top_names]\n    \n    plt.barh(range(len(top_indices)), top_importances, color='skyblue', edgecolor='black')\n    plt.yticks(range(len(top_indices)), display_names)\n    plt.xlabel('Importance Score')\n    plt.title(f'{dataset_name} - Top {top_n} Feature Importances')\n    plt.gca().invert_yaxis()  # Highest importance at top\n    plt.tight_layout()\n    plt.show()\n    \n    return rf, importances, indices\n\n# Analyze BBB dataset\nprint(\"Analyzing BBB dataset feature importance...\")\nrf_bbb, imp_bbb, idx_bbb = analyze_feature_importance(\n    X_bbb_train_scaled, y_bbb_train, feature_cols_bbb, \"BBB Dataset\"\n)",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Analyze Breast Cancer dataset\nprint(\"Analyzing Breast Cancer dataset feature importance...\")\nrf_bc, imp_bc, idx_bc = analyze_feature_importance(\n    X_bc_train_scaled, y_bc_train, feature_cols_bc, \"Breast Cancer Dataset\"\n)",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 6. Save Processed Data\n\nSave the preprocessed datasets for use in subsequent experiments:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Save processed datasets\nimport joblib\n\n# Create processed data directory\nprocessed_dir = \"../data/processed\"\nos.makedirs(processed_dir, exist_ok=True)\n\n# Save BBB processed data\nnp.save(f\"{processed_dir}/X_bbb_train.npy\", X_bbb_train_scaled)\nnp.save(f\"{processed_dir}/X_bbb_test.npy\", X_bbb_test_scaled)\nnp.save(f\"{processed_dir}/y_bbb_train.npy\", y_bbb_train)\nnp.save(f\"{processed_dir}/y_bbb_test.npy\", y_bbb_test)\nsmiles_train.to_csv(f\"{processed_dir}/smiles_bbb_train.csv\", index=False)\nsmiles_test.to_csv(f\"{processed_dir}/smiles_bbb_test.csv\", index=False)\n\n# Save Breast Cancer processed data\nnp.save(f\"{processed_dir}/X_bc_train.npy\", X_bc_train_scaled)\nnp.save(f\"{processed_dir}/X_bc_test.npy\", X_bc_test_scaled)\nnp.save(f\"{processed_dir}/y_bc_train.npy\", y_bc_train)\nnp.save(f\"{processed_dir}/y_bc_test.npy\", y_bc_test)\n\n# Save scalers\njoblib.dump(scaler_bbb, f\"{processed_dir}/scaler_bbb.pkl\")\njoblib.dump(scaler_bc, f\"{processed_dir}/scaler_bc.pkl\")\n\n# Save feature names\npd.Series(feature_cols_bbb).to_csv(f\"{processed_dir}/feature_names_bbb.csv\", index=False)\npd.Series(feature_cols_bc).to_csv(f\"{processed_dir}/feature_names_bc.csv\", index=False)\n\nprint(\"Processed data saved successfully!\")\nprint(f\"Files saved to: {processed_dir}\")\nprint(\"Contents:\")\nfor file in os.listdir(processed_dir):\n    if file.endswith(('.npy', '.csv', '.pkl')):\n        print(f\"  - {file}\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Summary\n\n**Preprocessing Complete!**\n\n### BBB Dataset:\n- **Input**: 2,039 SMILES strings → **Output**: 1,976 samples with 500+ features\n- **Features**: RDKit molecular descriptors + Mol2vec embeddings (300D)\n- **Preprocessing**: SMILES validation, descriptor calculation, feature cleaning\n- **Class distribution**: Balanced binary classification\n\n### Breast Cancer Dataset:\n- **Input**: 569 clinical samples → **Output**: 569 samples with 30 features  \n- **Features**: Clinical measurements (e.g., radius, texture, perimeter)\n- **Preprocessing**: Standard scaling, missing value handling\n- **Class distribution**: 212 malignant, 357 benign\n\n### Ready for Active Learning:\n- Data properly scaled and split (80/20)\n- Feature importance identified\n- Preprocessed data saved for experiments\n- Both datasets ready for comparative active learning studies\n\n**Next Step**: Dimensionality reduction analysis and visualization",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}