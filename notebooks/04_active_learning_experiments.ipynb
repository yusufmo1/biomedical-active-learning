{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Active Learning Experiments\n\nThis notebook demonstrates the core active learning experiments comparing different strategies on our biomedical datasets.\n\n## Experimental Design:\n\n### Datasets:\n1. **BBB (Blood-Brain Barrier)**: 1,976 molecular samples, PCA-reduced features\n2. **Breast Cancer**: 569 clinical samples, original 30 features\n\n### Active Learning Strategies:\n1. **Random Forest (RF)** with uncertainty sampling\n2. **Query-by-Committee (QBC)** with vote entropy\n\n### Sampling Methods:\n- **First 5**: Start with first 5 samples \n- **Stratified 5**: Start with 5 stratified samples\n\n### Evaluation:\n- Matthews Correlation Coefficient (MCC)\n- F1 Score  \n- ROC AUC\n- Delta MCC improvement vs full model",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import sys\nimport os\nsys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'src'))\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\nimport multiprocessing\nfrom joblib import Parallel, delayed\n\n# Machine learning\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.metrics import matthews_corrcoef, f1_score, roc_auc_score\nfrom scipy.stats import mode, entropy\n\n# Custom modules\nfrom active_learning.strategies import UncertaintySampling, QBCVoteEntropy\nfrom active_learning.learners import RandomForestAL, QueryByCommitteeAL\nfrom active_learning.experiments import ALExperiment\nfrom evaluation.metrics import ModelEvaluator\n\nprint(\"Libraries imported successfully!\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 1. Load Processed Data",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Load preprocessed data\nprocessed_dir = \"../data/processed\"\n\n# BBB Dataset (use PCA-reduced features)\ntry:\n    X_bbb_train = np.load(f\"{processed_dir}/X_bbb_train_pca.npy\")\n    X_bbb_test = np.load(f\"{processed_dir}/X_bbb_test_pca.npy\")\n    print(\"Loaded PCA-reduced BBB data\")\nexcept FileNotFoundError:\n    # Fallback to original features if PCA not available\n    X_bbb_train = np.load(f\"{processed_dir}/X_bbb_train.npy\")\n    X_bbb_test = np.load(f\"{processed_dir}/X_bbb_test.npy\")\n    print(\"Loaded original BBB data (PCA not found)\")\n\ny_bbb_train = np.load(f\"{processed_dir}/y_bbb_train.npy\")\ny_bbb_test = np.load(f\"{processed_dir}/y_bbb_test.npy\")\n\n# Breast Cancer Dataset\nX_bc_train = np.load(f\"{processed_dir}/X_bc_train.npy\")\nX_bc_test = np.load(f\"{processed_dir}/X_bc_test.npy\")\ny_bc_train = np.load(f\"{processed_dir}/y_bc_train.npy\")\ny_bc_test = np.load(f\"{processed_dir}/y_bc_test.npy\")\n\nprint(\"Dataset shapes:\")\nprint(f\"BBB - Train: {X_bbb_train.shape}, Test: {X_bbb_test.shape}\")\nprint(f\"BC  - Train: {X_bc_train.shape}, Test: {X_bc_test.shape}\")\nprint(f\"Class distributions:\")\nprint(f\"BBB train: {np.bincount(y_bbb_train)}, test: {np.bincount(y_bbb_test)}\")\nprint(f\"BC train:  {np.bincount(y_bc_train)}, test: {np.bincount(y_bc_test)}\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 2. Experimental Configuration",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Active Learning Configuration\nAL_CONFIG_BBB = {\n    'max_queries': -1,      # No query limit\n    'stop_ratio': 1.0,      # Use 100% of pool\n    'batch_size': 20,       # 20 samples per iteration\n    'n_runs': 5,            # Reduced for notebook demo (original: 10)\n    'stratified_seeds': [42, 10, 50, 100],\n    'rf_params': {'n_estimators': 100, 'random_state': 42},\n    'qbc_params': {},\n    'n_jobs': min(4, multiprocessing.cpu_count())  # Limit parallel jobs for notebook\n}\n\nAL_CONFIG_BC = {\n    'max_queries': -1,\n    'stop_ratio': 1.0,\n    'batch_size': 10,       # 10 samples per iteration\n    'n_runs': 5,            # Reduced for notebook demo\n    'stratified_seeds': [42, 10, 50, 100],\n    'rf_params': {'n_estimators': 100, 'random_state': 42},\n    'qbc_params': {},\n    'n_jobs': min(4, multiprocessing.cpu_count())\n}\n\nprint(\"Active Learning Configuration:\")\nprint(f\"BBB Config: {AL_CONFIG_BBB}\")\nprint(f\"BC Config:  {AL_CONFIG_BC}\")\nprint(f\"Available CPU cores: {multiprocessing.cpu_count()}\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 3. Helper Functions for Active Learning\n\nDue to the complexity of active learning experiments, this notebook demonstrates the key concepts. For full experiments, use the scripts in the `scripts/` directory.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Quick demonstration of active learning concept\ndef demonstrate_al_concept(X_train, y_train, X_test, y_test, dataset_name):\n    \"\"\"Demonstrate basic active learning concept\"\"\"\n    \n    print(f\"\\n=== {dataset_name} Active Learning Demo ===\")\n    \n    # 1. Train full model (baseline)\n    rf_full = RandomForestClassifier(n_estimators=100, random_state=42)\n    rf_full.fit(X_train, y_train)\n    \n    full_predictions = rf_full.predict(X_test)\n    full_mcc = matthews_corrcoef(y_test, full_predictions)\n    full_f1 = f1_score(y_test, full_predictions, average='weighted')\n    \n    print(f\"Full Model (trained on {len(X_train)} samples):\")\n    print(f\"  MCC: {full_mcc:.4f}\")\n    print(f\"  F1:  {full_f1:.4f}\")\n    \n    # 2. Simulate active learning with small initial set\n    initial_size = 10\n    al_indices = list(range(initial_size))  # First 10 samples\n    \n    rf_al = RandomForestClassifier(n_estimators=100, random_state=42)\n    rf_al.fit(X_train[al_indices], y_train[al_indices])\n    \n    al_predictions = rf_al.predict(X_test)\n    al_mcc = matthews_corrcoef(y_test, al_predictions)\n    al_f1 = f1_score(y_test, al_predictions, average='weighted')\n    \n    print(f\"Active Learning Model (trained on {len(al_indices)} samples):\")\n    print(f\"  MCC: {al_mcc:.4f}\")\n    print(f\"  F1:  {al_f1:.4f}\")\n    \n    # Performance comparison\n    mcc_diff = al_mcc - full_mcc\n    print(f\"Performance difference (AL - Full): {mcc_diff:.4f}\")\n    \n    if abs(mcc_diff) < 0.05:\n        print(\"✓ Active learning achieved comparable performance with much less data!\")\n    elif mcc_diff > 0:\n        print(\"✓ Active learning outperformed the full model!\")\n    else:\n        print(\"• Active learning performance below full model (expected with limited data)\")\n        \n    return {\n        'full_mcc': full_mcc,\n        'al_mcc': al_mcc,\n        'full_f1': full_f1,\n        'al_f1': al_f1,\n        'samples_used': len(al_indices),\n        'total_samples': len(X_train)\n    }\n\n# Run demonstrations\nbbb_demo = demonstrate_al_concept(X_bbb_train, y_bbb_train, X_bbb_test, y_bbb_test, \"BBB Dataset\")\nbc_demo = demonstrate_al_concept(X_bc_train, y_bc_train, X_bc_test, y_bc_test, \"Breast Cancer Dataset\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 4. For Complete Experiments\n\nFor full active learning experiments with multiple runs, parallel processing, and comprehensive evaluation, use the command-line scripts:\n\n```bash\n# Run complete experiments\ncd ../scripts\n\n# Prepare data\npython prepare_data.py --datasets bbb bc --output-dir ../data/processed\n\n# Run active learning experiments\npython run_experiments.py --datasets bbb bc --strategies rf qbc --sampling first5 stratified --runs 10\n\n# Evaluate results\npython evaluate.py --input-dir ../results --output-dir ../results/analysis\n\n# Generate reports\npython generate_report.py --input-dir ../results --output-dir ../results/reports\n```\n\nThis notebook demonstrates the core concepts. The scripts provide the full experimental pipeline used in the research.",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}